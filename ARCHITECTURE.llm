# PSH Architecture Reference for Large Language Models

Version: 0.101.0 (2025-01-06) – Parser Modularization & Token Pipeline Refresh  
Purpose: Optimized reference for LLMs working with the PSH codebase

## Quick Start

**Add a new builtin command**
1. Create module in `psh/builtins/` (example: `mycommand.py`) inheriting from `BuiltinCommand`
2. Register it inside `psh/builtins/registry.py` via `registry.register('name', MyCommand)`
3. Add behavioral tests in `tests/unit/builtins/` (or create a focused integration test under `tests/integration/builtins/`)

**Add a new shell option**
1. Extend `psh/core/state.py` to initialize the option in `ShellState.options`
2. Update any helpers in `psh/core/options.py` that should honor the option
3. Document CLI flags or builtin toggles if needed in `psh/builtins/parser_control.py`
4. Cover the option in `tests/integration/shell_options/test_shell_options_comprehensive.py`

**Modify parsing behavior**
1. Edit the appropriate module in `psh/parser/recursive_descent/parsers/` (e.g. `commands.py`, `control_structures.py`)
2. If context handling or configuration changes are required, adjust `ParserContext` in `psh/parser/recursive_descent/context.py`
3. Use `ParserConfig` (`psh/parser/config.py`) for feature flags; add presets via `ParserFactory` in `psh/parser/recursive_descent/support/factory.py`
4. Update validation or semantic rules in `psh/parser/validation/`
5. Add tests under `tests/test_parser_*.py` or `tests_new/unit/parser/`

**Extend expansion behavior**
1. Implement the feature in `psh/expansion/` (e.g., extend `parameter_expansion.py` or add a helper in `base.py`)
2. Register orchestration logic in `psh/expansion/manager.py`
3. Update ordering-sensitive logic in `ExpansionManager.expand_arguments()` (and relevant helpers)
4. Add unit tests in `tests/test_expansion_*.py`

**Add an AST visitor operation**
1. Create a visitor in `psh/visitor/` inheriting from `ASTVisitor`
2. Implement `visit_*` methods for the node types you care about
3. Wire the visitor into `Shell` or a command entry point if it becomes user-facing

## Component Hierarchy

```
psh/
├── shell.py                 # Main orchestrator (visitor executor only)
├── shell_parser.py          # Optional parser integration helper
├── composite_processor.py   # Post-lexer composite token merger
├── token_stream.py          # Parser-oriented token stream helpers
├── token_transformer.py     # Keyword/context normalization pass
├── pipeline/                # End-to-end pipeline builder utilities
│   └── builder.py
├── core/                    # Shared state, options, traps
│   ├── state.py             # ShellState and option plumbing
│   ├── scope.py             # Scope manager with POSIX semantics
│   ├── scope_enhanced.py    # Advanced scope features
│   ├── variables.py         # Variable types and exports
│   ├── exceptions.py        # Control-flow exceptions
│   └── trap_manager.py      # Signal/exit trap handling
├── lexer/                   # Unified modular lexer package
│   ├── modular_lexer.py     # Entry point for tokenization
│   ├── heredoc_lexer.py     # Tokenization with heredoc capture
│   ├── state_context.py     # Unified lexer context object
│   ├── transitions.py       # State machine transitions
│   ├── enhanced_context.py  # Rich metadata context helpers
│   ├── context_recognizer.py# Keyword and context detection
│   ├── quote_parser.py      # Unified quote parsing
│   ├── expansion_parser.py  # Pre-parse shell expansions
│   ├── expansion_validator.py
│   ├── quote_validator.py
│   ├── heredoc_collector.py
│   ├── token_stream_validator.py
│   ├── pure_helpers.py / enhanced_helpers.py
│   ├── token_parts.py / position.py / unicode_support.py
│   └── recognizers/         # Token recognizer registry (operators, keywords, literals, etc.)
├── token_types.py           # Unified Token & TokenType definitions
├── token_enhanced.py        # Token metadata helpers
├── parser/                  # Parser packages and registries
│   ├── __init__.py          # Exports unified recursive-descent API
│   ├── config.py            # ParserConfig & enums
│   ├── recursive_descent/
│   │   ├── parser.py        # Main Parser class (composite-aware)
│   │   ├── base.py / base_context.py
│   │   ├── context.py       # ParserContext & profiler
│   │   ├── helpers.py       # TokenGroups & ParseError
│   │   ├── parsers/         # commands, control_structures, statements, arrays, etc.
│   │   ├── enhanced/        # Optional enhanced parsing hooks
│   │   └── support/         # context_factory, factory, integration_manager, utils, word_builder
│   ├── combinators/         # Modular parser-combinator implementation
│   ├── parser_registry.py   # Runtime parser selection (strategy pattern)
│   ├── abstract_parser.py   # Interface shared by all parser implementations
│   ├── implementations/     # Recursive descent adapter + archived examples
│   ├── validation/          # Semantic analyzer & validation pipeline
│   └── visualization/       # AST renderers (ASCII, DOT, pretty)
├── expansion/               # POSIX expansion pipeline
│   ├── manager.py           # Orchestrates expansion order
│   ├── base.py              # Shared expansion helpers
│   ├── evaluator.py         # Word AST evaluation support
│   ├── variable.py / parameter_expansion.py
│   ├── command_sub.py / tilde.py / glob.py / word_splitter.py
├── executor/                # Visitor-based executor package
│   ├── core.py              # ExecutorVisitor (delegates to specialists)
│   ├── command.py / pipeline.py / control_flow.py
│   ├── array.py / function.py / subshell.py
│   └── strategies.py        # Builtin/function/external dispatch
├── io_redirect/             # Redirection management
│   ├── manager.py           # IOManager coordinating handlers
│   ├── file_redirect.py / heredoc.py / process_sub.py
├── scripting/               # Script execution pipeline
│   ├── base.py              # ScriptManager
│   ├── script_executor.py / source_processor.py
│   └── shebang_handler.py / script_validator.py
├── interactive/             # REPL, history, completion
│   ├── base.py              # InteractiveManager wiring
│   ├── repl_loop.py / prompt_manager.py / history_manager.py / signal_manager.py
│   └── completion_manager.py
├── brace_expansion.py / history_expansion.py / multiline_handler.py
├── builtins/                # Builtin commands (registry + implementations)
├── job_control.py           # Job control manager (JobManager)
├── utils/                   # Formatting helpers, path utilities, etc.
└── pipeline/                # Tokenize → parse → validate → execute helper
```

## Execution Pipeline

```
Input → Preprocessing → Tokenization → Token Normalization → Parsing → Validation → Expansion → Visitor Execution → Result
```

1. **Input Processing**
   - `input_preprocessing.py` handles line continuations
   - `history_expansion.HistoryExpander` expands `!` references
   - `brace_expansion.BraceExpander` expands `{…}` before lexing

2. **Tokenization (`psh/lexer/`)**
   - `ModularLexer` tokenizes with Unicode + contextual rules
   - `KeywordNormalizer` and `TokenTransformer` enforce context (case keywords, case terminators)
   - `tokenize_with_heredocs` collects heredoc bodies via `HeredocLexer`

3. **Token Post-processing**
   - `CompositeTokenProcessor` merges adjacent word-like tokens without whitespace into `CompositeToken`
   - `TokenStream` provides balanced collection/lookahead helpers for parsers
   - `token_stream_validator` ensures heredoc/token ordering sanity when integration requires it

4. **Parsing (`psh/parser/`)**
   - Default `Parser` (recursive descent) built from modular sub-parsers
   - `ParserContextFactory` wires contexts with config, tokens, and source text
   - `ParserFactory` produces preset configurations (strict POSIX, Bash-compatible, permissive, etc.)
   - Optional `ParserStrategy` switches between recursive descent and parser-combinator implementations

5. **Validation (optional)**
   - `parser/validation/validation_pipeline.py` provides semantic analysis and warnings
   - Invoked explicitly via pipeline builder or shell options

6. **Expansion (`psh/expansion/`)**
   - `ExpansionManager` enforces POSIX ordering across tilde, parameter, command, arithmetic, word splitting, globbing, quote removal
   - `ExpansionEvaluator` supports Word AST nodes emitted by parser

7. **Execution (`psh/executor/`)**
   - `ExecutorVisitor` walks AST nodes, leveraging specialized executors and `IOManager`
   - Returns final exit status; shell captures `$?`

## Orchestration & State

### Shell (`psh/shell.py`)
- Central entry point; orchestrates state, managers, parser strategy, and execution
- Initializes `ShellState`, alias/function/job managers, `ExpansionManager`, `IOManager`, `ScriptManager`, `InteractiveManager`, and `HistoryExpander`
- Uses `ParserStrategy` to honor parser selection (recursive descent vs. combinators); child shells inherit strategy
- Lazily instantiates `ExecutorVisitor` per execution to ensure fresh delegation wiring
- Key methods:
  - `run_command(cmd: str) -> int`
  - `execute_command_list(command_list: StatementList)`
  - `execute_toplevel(ast: TopLevel)` / `execute(ast)`
  - `execute_enhanced_test_statement(test_stmt: EnhancedTestStatement)`

### ShellState (`psh/core/state.py`)
- Centralizes environment, scope manager (`scope.py` / `scope_enhanced.py`), positional parameters, option flags, debug toggles, and stream references
- Tracks job control metadata, `$?`, `$!`, `$-`, and exported variables
- Provides option-specific helpers (xtrace, errexit, nounset) delegated to `psh/core/options.py`
- Coordinates trap installation through `TrapManager`

### Parser Integration Helpers
- `shell_parser.install_parser_integration(shell)` attaches a `ShellParser` instance that consumes shell options (`parser-mode`, `validate-context`, etc.) to build `ParserConfig`
- `psh/pipeline/builder.py` encapsulates tokenize → parse → validate → execute flows for tooling (`PipelineBuilder.build()` returns `ShellPipeline`)
- `parser/parser_registry.py` exposes `ParserStrategy` for runtime switching and instrumentation

## Token Pipeline Details

1. **Brace Expansion (`brace_expansion.py`)**
   - Expands `{a,b}` and ranges before lexing; failures fall back to raw input

2. **Modular Lexer (`lexer/modular_lexer.py`)**
   - Combines `LexerHelpers`, `StateHandlers`, `state_context.py`, and recognizer registry to emit unified `Token` instances
   - Uses `unicode_support.py` for identifier classification and POSIX fallback modes via `LexerConfig`
   - `recognizers/` includes operator, keyword, literal, whitespace, comment, and process-substitution recognizers

3. **Keyword Normalization & Token Transformation**
   - `lexer/keyword_normalizer.KeywordNormalizer` lowers + validates reserved words while preserving user identifiers; emits canonical keyword token types (e.g., WORD → THEN)
   - `token_transformer.TokenTransformer` enforces context rules (e.g., `;;` allowed only inside `case`)
   - Downstream code should match keywords via `matches_keyword`, `matches_keyword_type`, or `KeywordGuard` rather than inspecting `token.value`

4. **Composite Token Processing (`composite_processor.py`)**
   - Merges contiguous word-like tokens with no whitespace (e.g., `foo${bar}.txt`) into `CompositeToken`
   - Parser entry points can opt-in via `use_composite_processor=True`; default `parse()` keeps raw tokens unless higher-level integration enables composites

5. **Token Stream Utilities (`token_stream.py`)**
   - Provides `peek`, `advance`, balance collection, composite lookahead, and save/restore mechanics used across parser submodules

6. **Heredoc Support (`lexer/heredoc_lexer.py`, `lexer/heredoc_collector.py`)**
   - Collects heredoc bodies out-of-band while preserving token stream metadata
   - `tokenize_with_heredocs` returns `(tokens, heredoc_map)` for parser consumption

7. **Validation & Contracts**
   - `lexer/token_stream_validator.py` verifies lexer output contracts before parser integration when enhanced mode is active
   - `lexer/expansion_validator.py` / `lexer/quote_validator.py` provide sanity checks for complex lexing states

## Parser Package Highlights

### Recursive Descent Package (`psh/parser/recursive_descent/`)
- **`parser.py`**: Central `Parser` class orchestrating modular parsers; integrates `CompositeTokenProcessor`, uses `ParserContextFactory`, and exposes compatibility methods
- **`context.py`**: Defines `ParserContext`, profiling utilities, heredoc tracking, backtracking support
- **`base_context.py`**: Shared context-handling helpers (feature toggles, error policies)
- **`parsers/`**: Specialized modules for statements, commands, control structures, arithmetic, arrays, redirections, functions, and tests
- **`helpers.py`**: `ParseError`, `ErrorContext`, `TokenGroups`, and legacy compatibility shims
- **`enhanced/`**: Optional hook-ins for enriched error recovery and semantic-aware parsing (installed via `integration_manager`)
- **`support/`**:
  - `context_factory.py`: Builds `ParserContext` from tokens/config
  - `factory.py`: Provides `ParserFactory` presets and configuration validation helpers
  - `integration_manager.py`: Installs enhanced parsing features on demand
  - `utils.py`: Miscellaneous helpers (`parse_with_heredocs`, context adapters)
  - `word_builder.py`: Constructs Word AST nodes linking to expansion metadata

### Parser Configuration & Modes
- `parser/config.py`: `ParserConfig`, `ParsingMode`, `ErrorHandlingMode` with >40 toggles (validation, error collection, semantic analysis)
- `parser/parser_registry.py`: `ParserRegistry` and `ParserStrategy` enabling runtime parser swapping with metrics collection
- `parser/validation/`: `SemanticAnalyzer`, `ValidationPipeline`, rule definitions, warnings, and symbol tables
- `parser/visualization/`: Formatters for pretty, DOT, ASCII, and S-expression AST outputs
- **Keyword Helper Lifecycle**:
  - Lexer: `KeywordNormalizer` converts raw `WORD` tokens into canonical keyword types and updates metadata (`SemanticType.KEYWORD`)
  - Parser: modules use `matches_keyword`, `matches_keyword_type`, or `KeywordGuard` instead of comparing `token.value`
  - Tooling: `tests/unit/tooling/test_keyword_comparisons.py` guards against new string comparisons; use allowlists only for legacy archived examples
  - AST/Errors: `Token.normalized_value` offers a canonical string for diagnostics and suggestions

### Alternative Implementation (`psh/parser/combinators/`)
- Fully modular parser-combinator implementation with near parity to recursive descent (`core.py`, `tokens.py`, `commands.py`, `control_structures.py`, etc.)
- Registered via `ParserRegistry` (aliases: `"combinator"`, `"parser-combinator"`)
- Used for experimentation, benchmarking, and educational comparisons

## Expansion System

- `expansion/manager.py` orchestrates all expansion phases and exposes debugging toggles
- `expansion/base.py` centralizes normalization helpers and shared exceptions
- `expansion/variable.py` / `parameter_expansion.py` handle `$var`, `${var}`, slicing, modifiers
- `expansion/command_sub.py` executes command substitutions, integrating with shell inheritance rules
- `expansion/tilde.py` resolves `~` and `~user`
- `expansion/glob.py` performs pathname expansion while respecting quoting
- `expansion/word_splitter.py` applies `$IFS`-aware splitting
- `expansion/evaluator.py` walks Word AST nodes (produced when `ParserConfig.build_word_ast_nodes` is true)

## Execution & I/O

- `executor/core.py` implements `ExecutorVisitor`, delegating to specialized modules (`command.py`, `pipeline.py`, `control_flow.py`, `array.py`, `function.py`, `subshell.py`)
- `executor/strategies.py` encapsulates builtin/function/external command execution strategies
- `io_redirect/manager.py` coordinates file redirects, process substitutions, and heredoc handling; uses `FileRedirector`, `HeredocHandler`, `ProcessSubstitutionHandler`
- `job_control.JobManager` integrates job monitoring, shell options (`monitor`, `notify`), and process state tracking

## Supporting Systems

- `scripting/base.py` (`ScriptManager`) manages script execution, sourcing, and shebang handling
- `scripting/script_validator.py` / `source_processor.py` provide linting and pre-processing for scripts
- `interactive/base.py` coordinates REPL, prompt, history, and signal managers; `repl_loop.py` drives interactive shells
- `input_sources.py`, `multiline_handler.py`, `line_editor.py` support multi-line editing and input abstraction
- `token_enhanced.py` adds metadata attachment to tokens (context, source mapping)
- `utils/token_formatter.py` and friends provide debugging/trace formatting

## Data Flow Examples

### Simple Command: `echo "Hello $USER"`
1. **Tokenizer**: WORD(`echo`), STRING(`Hello $USER`)
2. **Composite Processor**: STRING + (no adjacent tokens) → unchanged
3. **Parser**: `SimpleCommand(args=["echo", "Hello $USER"])`
4. **Expansion**: `"Hello $USER"` → `"Hello alice"` (quote preserves spacing)
5. **Executor**: Runs builtin `echo`, returns status `0`

### Composite Argument: `file${N}.txt`
1. **Tokenizer**: WORD(`file`), VARIABLE(`N`), WORD(`.txt`)
2. **Composite Processor**: merges into COMPOSITE(`file${N}.txt`)
3. **Parser**: Treats composite as single argument in `SimpleCommand`
4. **Expansion**: Variable expansion occurs inside composite preserving literal parts

### Pipeline With Validation: `ls | grep test`
1. **PipelineBuilder**: `.tokenize()` uses `ModularLexer`
2. **Parser**: Produces `Pipeline([SimpleCommand("ls"), SimpleCommand("grep", "test")])`
3. **ValidationPipeline** (optional): Checks semantic rules (e.g., globbing warnings)
4. **ExecutorVisitor**: Sets up pipe, forks commands, returns exit status of final command (with `pipefail` awareness)

## Extension Points

**New Builtin Command**
```python
# psh/builtins/mybuiltin.py
from psh.builtins.base import BuiltinCommand

class MyBuiltin(BuiltinCommand):
    def execute(self, args: list[str], shell: 'Shell') -> int:
        # Implementation
        return 0

# Register in psh/builtins/registry.py
registry.register('mybuiltin', MyBuiltin)
```

**New Parser Rule**
1. Add parsing logic in the relevant module under `psh/parser/recursive_descent/parsers/`
2. Update helper utilities or token groups if the rule needs new token classifications
3. Provide validation rules in `psh/parser/validation/validation_rules.py` if semantics require checks

**New Expansion Type**
1. Implement expander in `psh/expansion/` (e.g., `new_expansion.py`)
2. Invoke it from `ExpansionManager.expand_arguments()` (or the specific helper it delegates to) in the proper POSIX order slot
3. Update `ExpansionEvaluator` when Word AST integration is required
4. Add regression coverage in `tests/test_expansion_new_feature.py`

## Architecture Invariants

1. **Centralized State**: All mutable shell state flows through `ShellState`
2. **Component Isolation**: Managers interact via `Shell` references, not global state
3. **Visitor Execution**: AST nodes remain data-only; behavior lives in visitors/executors
4. **POSIX Expansion Order**: Expansion phases must remain in standard order
5. **Parser Feature Flags**: `ParserConfig` governs all behavior toggles; avoid hard-coded feature switches
6. **Composite Token Safety**: Composite merging must preserve original token boundaries for metadata consumers
7. **Exit Status Discipline**: Every execution path returns an integer exit status

## Testing Conventions

- Pytest entry: `pytest` (configured via `pytest.ini`)
- Traditional tests live in `tests/`; incremental refactors under `tests_new/unit/`
- Lexer tests: `tests/test_lexer_*.py` (add new focused cases alongside existing files); keyword normalization goldens live in `tests/unit/lexer/test_keyword_normalizer_golden.py`
- Parser tests: `tests/test_parser_*.py`, combinator parity suites in `tests_new/unit/parser/`
- Parser parity: `tests/test_parser_feature_parity.py` has keyword-heavy scenarios to keep recursive descent and combinator implementations aligned
- Expansion tests: `tests/test_expansion_*.py`
- Executor/integration: `tests/test_executor_*.py`, `tests/test_shell_*.py`, plus golden scripts in `conformance_tests/`
- Tooling checks: `tests/unit/tooling/test_keyword_comparisons.py` prevents new raw keyword comparisons
- Use fixtures from `conftest.py` (`shell`, `tokenizer`, etc.) for consistency

## Performance Considerations

1. **Lexer**: State machine minimizes backtracking; Unicode classification cached in helpers
2. **Composite Processor**: Linear scan with adjacency checks, negligible overhead
3. **Parser**: Modular recursive descent with shared `ParserContext` reduces redundant allocations; composites limit word concatenation work
4. **Validation**: Optional; keep disabled in performance-sensitive modes
5. **Executor**: Strategy pattern avoids repeated type checks and supports caching
6. **Expansion**: Lazy evaluation where possible; Word AST mode offers better caching at cost of tree building

## Known Limitations

1. **Python Recursion Limits**: Deeply nested shell functions may exceed Python recursion depth
2. **Pytest Output Capture**: Command substitution may interfere with pytest’s stdout capture in certain tests
3. **Builtin Redirections**: Builtins re-use process substitution & FD juggling; some complex redirection combinations still require caution
4. **Composite Token Metadata**: While `CompositeToken` preserves components, quote attribution can require consulting `components` for precise semantics

## Quick Reference

- **Add builtin**: `psh/builtins/` + `psh/builtins/registry.py`
- **Modify tokenization**: `psh/lexer/modular_lexer.py` and recognizers; configs via `LexerConfig` in `psh/lexer/position.py`
- **Keyword normalization**: `psh/lexer/keyword_normalizer.py`
- **Token transformation**: `psh/token_transformer.py`
- **Composite tokens**: `psh/composite_processor.py`
- **Token stream utilities**: `psh/token_stream.py`
- **Parser entry point**: `psh/parser/__init__.py` (`parse`, `ParserFactory`)
- **Parser context**: `psh/parser/recursive_descent/context.py`
- **Parser presets**: `psh/parser/recursive_descent/support/factory.py`
- **Parser registry/strategy**: `psh/parser/parser_registry.py`
- **Parser validation**: `psh/parser/validation/validation_pipeline.py`
- **Expansion manager**: `psh/expansion/manager.py`
- **Executor visitor**: `psh/executor/core.py`
- **IO manager**: `psh/io_redirect/manager.py`
- **Pipeline builder**: `psh/pipeline/builder.py`
- **Shell options**: `psh/core/state.py`, behaviors in `psh/core/options.py`
- **Job control**: `psh/job_control.py`
- **Interactive shell**: `psh/interactive/base.py`, `psh/interactive/repl_loop.py`
- **Script execution**: `psh/scripting/base.py`, `psh/scripting/script_executor.py`

## Maintenance

1. Update version/date header when architecture changes land (`psh/version.py` authoritative)
2. Refresh component hierarchy for new modules or reorganizations
3. Adjust execution pipeline notes when token/parsing steps shift
4. Keep extension points and quick reference aligned with latest module paths
5. Cross-check against `ARCHITECTURE.md` and release notes; this file supersedes older human-focused docs when conflicts arise
6. Document new invariants and known limitations as they appear

Related documentation:
- `ARCHITECTURE.md` – human-readable guide (pending update to 0.101.0)
- `ENHANCED_PARSER_INTEGRATION_PLAN.md` – historical context for parser integration
- `LEXER_REFACTORING_STATUS.md` / `LEXER_REFACTORING_PLAN.md` – lexer migration notes
- `PARSER_HIGH_PRIORITY_IMPLEMENTATION_PLAN.md` – historical plan for parser enhancements
- `RELEASE_NOTES_v0.91.3.md` and `psh/version.py` – change history
- `CLAUDE.md`, `AGENTS.md` – collaboration guidelines for agentic contributors
- `docs/keyword_helper_cookbook.md` – practical guide for keyword normalization and parser integration
- `docs/architecture_recommendations.md` – ongoing suggestions for structural improvements and refactors
