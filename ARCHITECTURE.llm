# PSH Architecture Reference for Large Language Models

Version: 0.91.3 (2025-01-17) - Lexer Deprecation Plan Complete  
Purpose: Optimized reference for LLMs working with PSH codebase

## Quick Start

### Making Common Changes

**Add a new builtin command:**
1. Create file in `psh/builtins/` (e.g., `mycommand.py`)
2. Implement command class inheriting from `BuiltinCommand`
3. Register in `psh/builtins/registry.py`

**Add a new shell option:**
1. Add to `psh/core/options.py` OPTION_HANDLERS
2. Update `psh/core/state.py` if needed
3. Add tests in `tests/test_shell_options.py`

**Modify parsing behavior:**
1. Edit relevant file in `psh/parser/` package
2. Update delegation in `psh/parser/main.py` if new parser modules added
3. Use ParserConfig for configuration changes
4. Add validation rules in `psh/parser/validation/` if needed
5. Add tests in `tests/test_parser_*.py` or `tests_new/unit/parser/`

**Modify expansion behavior:**
1. Edit relevant file in `psh/expansion/`
2. Update `ExpansionManager.expand_argument()` if order changes
3. Add tests in `tests/test_*_expansion.py`

**Add AST visitor operation:**
1. Create new visitor in `psh/visitor/`
2. Inherit from `ASTVisitor[T]`
3. Implement `visit_*` methods for each node type

## Component Hierarchy

```
psh/
├── shell.py                 # Main orchestrator (~490 lines)
├── core/                    # Shared state and exceptions
│   ├── state.py            # Central state management
│   ├── scope.py            # Variable scoping
│   ├── variables.py        # Variable types (arrays)
│   ├── exceptions.py       # Control flow exceptions
│   └── options.py          # Shell option handlers
├── input_preprocessing.py   # Line continuation handling
├── lexer/                   # Modular lexer package (v0.58.0+)
│   ├── __init__.py         # Clean public API
│   ├── core.py            # Main StateMachineLexer class
│   ├── helpers.py         # LexerHelpers mixin with utility methods
│   ├── state_handlers.py  # StateHandlers mixin with state machine logic
│   ├── constants.py       # All lexer constants and character sets
│   ├── unicode_support.py # Unicode character classification
│   ├── token_parts.py     # TokenPart and RichToken classes
│   ├── position.py        # Position tracking, error handling, and lexer configuration
│   ├── state_context.py   # Unified LexerContext (Phase 1)
│   ├── transitions.py     # State transition management (Phase 1)
│   ├── pure_helpers.py    # Stateless helper functions (Phase 2)
│   ├── enhanced_helpers.py # API wrapper for pure helpers (Phase 2)
│   ├── quote_parser.py    # Unified quote parsing (Phase 3)
│   ├── expansion_parser.py # Expansion parsing (Phase 3)
│   ├── unified_lexer.py   # Integrates unified parsers (Phase 3)
│   ├── modular_lexer.py   # ModularLexer with all phases (Phase 4)
│   └── recognizers/       # Token recognition system (Phase 4)
│       ├── __init__.py
│       ├── base.py        # TokenRecognizer interface
│       ├── operator.py    # Operator recognition
│       ├── keyword.py     # Keyword recognition
│       ├── literal.py     # Literal recognition
│       ├── whitespace.py  # Whitespace handling
│       ├── comment.py     # Comment recognition
│       └── registry.py    # Recognizer registry
├── token_types.py          # Unified Token class with metadata and context (v0.91.3)
├── parser/                  # Enhanced parser package with comprehensive configuration and validation
│   ├── __init__.py         # Clean public API with backward compatibility
│   ├── main.py            # Main Parser class with delegation orchestration and ParserContext
│   ├── base.py            # Base parser class with token management
│   ├── base_context.py    # ContextBaseParser using ParserContext (v0.85.0)
│   ├── helpers.py         # Helper classes and token groups
│   ├── commands.py        # Command and pipeline parsing
│   ├── statements.py      # Statement list and control flow parsing
│   ├── control_structures.py # All control structures (if, while, for, case, select)
│   ├── tests.py           # Enhanced test expression parsing with regex support
│   ├── arithmetic.py      # Arithmetic command and expression parsing
│   ├── redirections.py    # I/O redirection parsing
│   ├── arrays.py          # Array initialization and assignment parsing
│   ├── functions.py       # Function definition parsing
│   ├── utils.py           # Utility functions and heredoc handling
│   ├── config.py          # Parser configuration system (v0.85.0)
│   ├── factory.py         # ParserFactory with preset configurations (v0.85.0)
│   ├── context.py         # Centralized ParserContext (v0.85.0)
│   ├── context_factory.py # Context factory and creation utilities (v0.85.0)
│   ├── context_snapshots.py # Context snapshots for backtracking (v0.85.0)
│   ├── validation/        # AST validation system (v0.85.0)
│   │   ├── semantic_analyzer.py # Semantic analysis with visitor pattern
│   │   ├── validation_rules.py  # Modular validation rules
│   │   ├── symbol_table.py      # Symbol table management
│   │   ├── warnings.py          # Warning system with severity levels
│   │   └── validation_pipeline.py # Validation orchestration
│   └── visualization/     # Parse tree visualization (v0.85.0)
│       ├── ast_formatter.py    # Pretty printer for human-readable output
│       ├── dot_generator.py    # Graphviz DOT format for diagrams
│       └── ascii_tree.py       # ASCII tree renderer for terminal
├── ast_nodes.py            # AST node definitions
├── visitor/                # Visitor pattern operations
│   ├── base.py            # Base visitor classes
│   └── executor_visitor.py # Default executor (visitor pattern)
├── expansion/              # Shell expansions
│   ├── manager.py         # Orchestrates expansions
│   ├── variable.py        # Variable/parameter expansion
│   ├── command_sub.py     # Command substitution
│   ├── tilde.py          # Tilde expansion
│   └── glob.py           # Pathname expansion
├── executor/               # Modular executor package (v0.68.0)
│   ├── __init__.py        # Public API exports
│   ├── core.py            # Main ExecutorVisitor (542 lines)
│   ├── command.py         # Simple command execution
│   ├── pipeline.py        # Pipeline execution
│   ├── control_flow.py    # Control structures
│   ├── array.py           # Array operations
│   ├── function.py        # Function execution
│   ├── subshell.py        # Subshell/brace groups
│   ├── context.py         # ExecutionContext
│   └── strategies.py      # Command strategies
├── io_redirect/            # I/O redirection
│   ├── manager.py        # Orchestrates redirections
│   ├── file_redirect.py  # File redirections
│   ├── heredoc.py        # Here documents
│   └── process_sub.py    # Process substitution
├── interactive/            # Interactive shell features
│   ├── repl_loop.py      # Read-eval-print loop
│   ├── prompt_manager.py # PS1/PS2 prompts
│   └── history_manager.py # Command history
├── scripting/              # Script execution
│   └── script_executor.py # Execute script files
├── builtins/               # Built-in commands
│   ├── registry.py       # Central registry
│   └── *.py             # Individual builtins
└── utils/                  # Utility modules
```

## Execution Pipeline

```
Input → Preprocessing → Tokenization → Parsing → AST → Visitor Execution → Result

1. Input Processing:
   - Line continuation (\<newline>) removal
   - History expansion (!!, !n, etc.)
   - Brace expansion ({a,b}, {1..5})

2. Tokenization (lexer/ package):
   - 4-phase refactored architecture:
     - Phase 1: Unified state management (LexerContext)
     - Phase 2: Pure function helpers (15+ functions)
     - Phase 3: Unified quote/expansion parsing
     - Phase 4: Modular token recognition system
   - Priority-based recognizer dispatch
   - Advanced state machine with Unicode support
   - LexerConfig system for feature control
   - Position tracking with enhanced error handling
   - Unicode-aware character classification
   - POSIX compatibility mode
   - Produces RichToken objects with metadata
   - Preserves quote information for expansion
   - Full backward compatibility maintained

3. Parsing (parser/ package):
   - Enhanced modular parser package with comprehensive configuration and validation
   - 8 core modules plus extensive configuration and validation systems
   - Delegation-based main parser orchestrating specialized parsers
   - Centralized ParserContext for unified state management
   - Parser configuration system with multiple parsing modes
   - AST validation system with semantic analysis
   - Parse tree visualization in multiple formats
   - Advanced error recovery with multi-error collection
   - Complete backward compatibility with existing API
   - Produces validated AST (ast_nodes.py) with optional semantic analysis
   - Handles all shell constructs with comprehensive error recovery

4. Execution (executor/ package):
   - Modular executor package with delegation architecture
   - Main ExecutorVisitor delegates to specialized executors
   - ExecutionContext manages execution state
   - Strategy pattern for command execution
   - Returns exit status
```

## Key Components

### Shell (shell.py)
**Purpose:** Central orchestrator coordinating all components
**Key Methods:**
- `run_command(cmd: str) -> int` - Execute a command string
- `interactive_loop()` - Start interactive REPL
- `execute_ast(ast: ASTNode) -> int` - Execute parsed AST

**Initialized Components:**
```python
self.state = ShellState()
self.expansion_manager = ExpansionManager(self)
self.io_manager = IORedirectManager(self)
# Executor is now created on-demand in execute methods
self.job_manager = JobControlManager(self)
self.alias_manager = AliasManager(self)
self.function_manager = FunctionManager(self)
self.builtin_registry = BuiltinRegistry(self)
self.interactive_manager = InteractiveManager(self)
self.script_manager = ScriptManager(self)
```

### ShellState (core/state.py)
**Purpose:** Centralized state for entire shell
**Key Attributes:**
- `environment: Dict[str, str]` - Environment variables
- `scope_manager: EnhancedScopeManager` - Variable scopes
- `positional_params: List[str]` - $1, $2, etc.
- `last_exit_status: int` - $?
- `shell_pid: int` - $$
- `last_bg_pid: Optional[int]` - $!
- `options: Dict[str, bool]` - Shell options

### ExecutorVisitor (executor/core.py)
**Purpose:** Main execution engine using visitor pattern with delegation
**Architecture:**
- Core visitor (~542 lines) delegates to specialized executors
- ExecutionContext manages execution state
- Strategy pattern for command type execution

**Specialized Executors:**
```python
# executor/command.py - Simple command execution
self.command_executor = CommandExecutor(shell)

# executor/pipeline.py - Pipeline execution  
self.pipeline_executor = PipelineExecutor(shell)

# executor/control_flow.py - Control structures
self.control_flow_executor = ControlFlowExecutor(shell)

# executor/array.py - Array operations
self.array_executor = ArrayOperationExecutor(shell)

# executor/function.py - Function execution
self.function_executor = FunctionOperationExecutor(shell)

# executor/subshell.py - Subshells and brace groups
self.subshell_executor = SubshellExecutor(shell)
```

### ExpansionManager (expansion/manager.py)
**Purpose:** Orchestrate all expansions in correct order
**Expansion Order:**
1. Tilde expansion (~, ~user)
2. Variable expansion ($var, ${var})
3. Command substitution ($(...), `...`)
4. Arithmetic expansion ($((...)))
5. Word splitting (on $IFS)
6. Pathname expansion (*, ?, [...])
7. Quote removal

### Lexer Package (lexer/) - Unified Architecture (v0.91.3)
**Purpose:** Unified modular lexer with enhanced features as standard
**Note:** Enhanced lexer deprecation plan completed in v0.91.3. All enhanced features are now built-in standard throughout PSH operation. Compatibility code removed.

**Core Components (Original v0.58.0):**
- **StateMachineLexer** (core.py): Main lexer class combining mixins
- **LexerHelpers** (helpers.py): Utility methods for balanced parsing, operators, word termination
- **StateHandlers** (state_handlers.py): All state machine transition logic
- **Constants** (constants.py): Character sets, operators, keywords
- **Unicode Support** (unicode_support.py): Unicode character classification with POSIX fallback
- **Token Parts** (token_parts.py): TokenPart and RichToken definitions
- **Position Tracking** (position.py): Position, LexerState, LexerConfig, error handling

**Refactored Components (Phases 1-4):**
- **Phase 1 - State Management:**
  - `state_context.py`: Unified LexerContext with all state
  - `transitions.py`: State transition management with history
  - `enhanced_state_machine.py`: Enhanced lexer using unified state
- **Phase 2 - Pure Helpers:**
  - `pure_helpers.py`: 15+ stateless helper functions
  - `enhanced_helpers.py`: Wrapper maintaining existing API
- **Phase 3 - Unified Parsing:**
  - `quote_parser.py`: Unified quote parsing with configurable rules
  - `expansion_parser.py`: All expansion types ($VAR, ${VAR}, $(...), $((...)))
  - `unified_lexer.py`: Integrates unified parsers
- **Phase 4 - Token Recognition:**
  - `recognizers/base.py`: TokenRecognizer abstract interface
  - `recognizers/operator.py`: Shell operators with context awareness
  - `recognizers/keyword.py`: Shell keywords with position validation
  - `recognizers/literal.py`: Words, identifiers, and numbers
  - `recognizers/whitespace.py`: Whitespace handling
  - `recognizers/comment.py`: Comment recognition
  - `recognizers/registry.py`: Priority-based recognizer dispatch
  - `modular_lexer.py`: ModularLexer integrating all systems

**Key Features:**
- 4-phase refactored architecture with backward compatibility
- Unified state management with immutable snapshots
- Pure function helpers for testability
- Configurable quote and expansion parsing
- Priority-based token recognition system
- Unicode-aware character classification
- POSIX compatibility mode for ASCII-only operation
- Comprehensive error handling with position tracking
- Clean modular design with extensibility points

**Unicode Functions:**
```python
def is_identifier_start(char: str, posix_mode: bool = False) -> bool
def is_identifier_char(char: str, posix_mode: bool = False) -> bool  
def is_whitespace(char: str, posix_mode: bool = False) -> bool
def normalize_identifier(name: str, posix_mode: bool = False, case_sensitive: bool = True) -> str
def validate_identifier(name: str, posix_mode: bool = False) -> bool
```

**Architecture:**
```python
# Mixin-based design for modularity
class StateMachineLexer(LexerHelpers, StateHandlers):
    def __init__(self, input_string: str, config: Optional[LexerConfig] = None):
        # Initialize lexer with modular components
        pass

# Configuration system
class LexerConfig:
    # Core features
    enable_double_quotes: bool = True
    enable_single_quotes: bool = True
    enable_variable_expansion: bool = True
    # Unicode support
    posix_mode: bool = False
    unicode_identifiers: bool = True
    case_sensitive: bool = True
    # Error handling
    strict_mode: bool = False
    recovery_mode: bool = True
```

### Enhanced Parser System (v0.85.0)

**Parser Configuration:**
```python
# Multiple parsing modes
parser = ParserFactory.create_strict_posix_parser(tokens, source_text)
parser = ParserFactory.create_bash_compatible_parser(tokens, source_text)
parser = ParserFactory.create_permissive_parser(tokens, source_text)
parser = ParserFactory.create_educational_parser(tokens, source_text)

# Custom configuration
config = ParserConfig(
    parsing_mode=ParsingMode.EDUCATIONAL,
    enable_validation=True,
    collect_errors=True,
    max_errors=50
)
parser = Parser(tokens, config=config)
```

**Centralized Parser Context:**
```python
# All parser state in unified context
class ParserContext:
    tokens: List[Token]
    current: int
    config: ParserConfig
    errors: List[ParseError]
    scope_stack: List[str]
    profiler: Optional[ParserProfiler]
    
    def enter_scope(self, scope: str): ...
    def consume(self, token_type: TokenType): ...
    def match(self, *token_types: TokenType): ...
```

**AST Validation:**
```python
# Semantic analysis with validation
analyzer = SemanticAnalyzer()
errors, warnings = analyzer.analyze(ast)

# Validation rules
validator = ValidationPipeline()
report = validator.validate(ast)
```

**Parse Tree Visualization:**
```python
# Multiple output formats
formatter = ASTPrettyPrinter()
dot_generator = ASTDotGenerator()
tree_renderer = ASTAsciiTreeRenderer()

# CLI integration
psh --debug-ast=pretty -c "if true; then echo hi; fi"
parse-tree -f dot "for i in 1 2 3; do echo $i; done"
show-ast "case $var in pattern) echo match;; esac"
```

### Key Interfaces

**BuiltinCommand (builtins/base.py):**
```python
class BuiltinCommand(ABC):
    @abstractmethod
    def execute(self, args: List[str], shell: 'Shell') -> int:
        """Execute builtin with args, return exit status"""
```

**ASTVisitor (visitor/base.py):**
```python
class ASTVisitor(Generic[T], ABC):
    def visit(self, node: ASTNode) -> T:
        """Visit a node, dispatching to visit_* method"""
        method_name = f'visit_{node.__class__.__name__}'
        visitor = getattr(self, method_name, self.generic_visit)
        return visitor(node)
```

**ParserConfig (parser/config.py):**
```python
@dataclass
class ParserConfig:
    parsing_mode: ParsingMode = ParsingMode.BASH_COMPAT
    error_handling: ErrorHandlingMode = ErrorHandlingMode.STRICT
    enable_validation: bool = False
    collect_errors: bool = False
    max_errors: int = 10
    # ... 40+ more configuration options
```


## Data Flow Examples

### Simple Command: `echo "Hello $USER"`
1. **Tokenize:** [WORD("echo"), STRING("Hello $USER")]
2. **Parse:** SimpleCommand(args=["echo", "Hello $USER"])
3. **Execute:**
   - Expand arguments: ["echo", "Hello alice"]
   - Resolve command: builtin "echo"
   - Execute builtin: outputs "Hello alice"
   - Return: exit status 0

### Pipeline: `ls | grep test`
1. **Parse:** Pipeline([SimpleCommand("ls"), SimpleCommand("grep", "test")])
2. **Execute:**
   - Create pipe
   - Fork for ls (redirect stdout to pipe)
   - Fork for grep (redirect stdin from pipe)
   - Wait for both processes
   - Return: exit status of grep

### Variable Assignment: `X=10; echo $X`
1. **Parse:** StatementList([SimpleCommand with assignment, SimpleCommand])
2. **Execute:**
   - First command: set variable X=10
   - Second command: expand $X to "10", echo it
   - Return: exit status 0

## Extension Points

### Adding Features

**New Builtin Command:**
```python
# psh/builtins/mybuiltin.py
from psh.builtins.base import BuiltinCommand

class MyBuiltin(BuiltinCommand):
    def execute(self, args: List[str], shell: 'Shell') -> int:
        # Implementation
        return 0

# Register in psh/builtins/registry.py
self.register('mybuiltin', MyBuiltin)
```

**New AST Operation:**
```python
# psh/visitor/myvisitor.py
from psh.visitor.base import ASTVisitor

class MyVisitor(ASTVisitor[None]):
    def visit_SimpleCommand(self, node: SimpleCommand) -> None:
        # Process command
        pass
```

**New Expansion Type:**
1. Add expander class in `psh/expansion/`
2. Integrate into `ExpansionManager.expand_argument()`
3. Consider expansion order requirements

## Architecture Invariants

1. **State Centralization:** All state goes through ShellState
2. **Component Isolation:** Components communicate through Shell instance
3. **Visitor Pattern:** AST nodes are data-only, operations in visitors
4. **Exit Status:** All execution returns integer exit status
5. **Fork for External:** External commands always fork()
6. **Expansion Order:** Must follow POSIX expansion order

## Testing Conventions

**Test Organization:**
- Unit tests: `test_<component>.py`
- Integration tests: `test_integration.py`
- Bash comparison: `tests/comparison/test_bash_*.py`

**Test Patterns:**
```python
def test_feature(shell):  # shell fixture from conftest.py
    result = shell.run_command("command")
    assert result == 0  # exit status
```

## Performance Considerations

1. **Tokenizer:** State machine minimizes backtracking
2. **Parser:** Single-pass recursive descent
3. **Visitor:** Direct dispatch via Python method lookup
4. **Expansion:** Lazy evaluation where possible
5. **Subprocess:** Fork only when necessary

## Known Limitations

1. **Deep Recursion:** Python stack limits affect shell function recursion
2. **Pytest Capture:** Command substitution output capture issues in tests
3. **Builtin Redirections:** Would require forking builtins
4. **Composite Token Quotes:** Some quote information lost in parser

## Common Patterns

### Manager Pattern
```python
class SomeManager:
    def __init__(self, shell: 'Shell'):
        self.shell = shell
        self.state = shell.state
```

### Visitor Method
```python
def visit_NodeType(self, node: NodeType) -> int:
    # Process node
    # Recurse to children if needed
    # Return exit status
```

### Builtin Implementation
```python
class MyBuiltin(BuiltinCommand):
    def execute(self, args: List[str], shell: 'Shell') -> int:
        # Validate arguments
        # Perform operation
        # Update state if needed
        # Return exit status
```

## Quick Reference

### File Locations
- **Add builtin:** `psh/builtins/` + register in `registry.py`
- **Modify parsing:** `psh/parser/` package + update delegation in `main.py` if needed
- **Parser configuration:** `psh/parser/config.py` (ParserConfig, ParsingMode)
- **Parser factory:** `psh/parser/factory.py` (ParserFactory with presets)
- **Parser context:** `psh/parser/context.py` (ParserContext, ParserProfiler)
- **Context factory:** `psh/parser/context_factory.py` (context creation utilities)
- **Context snapshots:** `psh/parser/context_snapshots.py` (backtracking support)
- **AST validation:** `psh/parser/validation/` (semantic analysis, validation rules)
- **Parse visualization:** `psh/parser/visualization/` (AST formatters, tree renderers)
- **Change expansion:** `psh/expansion/` + `manager.py`
- **Add shell option:** `psh/core/options.py`
- **Modify tokenization:** `psh/lexer/` package (see below for specific areas)
- **Original lexer:** `psh/lexer/core.py`, `helpers.py`, `state_handlers.py`
- **Lexer constants:** `psh/lexer/constants.py`
- **Unicode support:** `psh/lexer/unicode_support.py`
- **Position tracking:** `psh/lexer/position.py`
- **Configure lexer features:** `LexerConfig` class in `psh/lexer/position.py`
- **State management:** `psh/lexer/state_context.py`, `transitions.py` (Phase 1)
- **Pure helpers:** `psh/lexer/pure_helpers.py` (Phase 2)
- **Quote parsing:** `psh/lexer/quote_parser.py` (Phase 3)
- **Expansion parsing:** `psh/lexer/expansion_parser.py` (Phase 3)
- **Token recognizers:** `psh/lexer/recognizers/` (Phase 4)
- **Integrated lexer:** `psh/lexer/modular_lexer.py` (Phase 4)
- **Parser components:** `psh/parser/commands.py`, `psh/parser/control_structures.py`, etc.
- **Parser helpers:** `psh/parser/helpers.py` (TokenGroups, ParseError, etc.)

### Key Classes
- `Shell` - Main orchestrator
- `ShellState` - Central state
- `ExecutorVisitor` - Main executor with delegation
- `ExecutionContext` - Execution state management
- `CommandExecutor` - Simple command execution
- `PipelineExecutor` - Pipeline execution
- `ExpansionManager` - Expansion orchestrator
- `Parser` - Enhanced modular parser with ParserContext integration
- `ParserContext` - Centralized parser state management (v0.85.0)
- `ParserConfig` - Comprehensive parser configuration (v0.85.0)
- `ParserFactory` - Factory with preset configurations (v0.85.0)
- `ParserContextFactory` - Context creation utilities (v0.85.0)
- `SemanticAnalyzer` - AST semantic analysis (v0.85.0)
- `ValidationPipeline` - Validation orchestration (v0.85.0)
- `ASTPrettyPrinter` - Human-readable AST formatting (v0.85.0)
- `ASTDotGenerator` - Graphviz DOT format generator (v0.85.0)
- `ASTAsciiTreeRenderer` - Terminal ASCII tree display (v0.85.0)
- `CommandParser` - Command and pipeline parsing
- `ControlStructureParser` - Control structure parsing
- `StateMachineLexer` - Original tokenizer with mixin architecture
- `LexerHelpers` - Mixin with utility methods
- `StateHandlers` - Mixin with state machine logic
- `LexerConfig` - Lexer configuration and feature control
- `PositionTracker` - Position tracking for error handling
- `LexerContext` - Unified state representation (Phase 1)
- `StateManager` - State transition management (Phase 1)
- `UnifiedQuoteParser` - Configurable quote parsing (Phase 3)
- `ExpansionParser` - All expansion types (Phase 3)
- `TokenRecognizer` - Base interface for recognizers (Phase 4)
- `RecognizerRegistry` - Priority-based dispatch (Phase 4)
- `ModularLexer` - Integrated lexer with all phases (Phase 4)

### Important Methods
- `shell.run_command(cmd)` - Execute command
- `expansion_manager.expand_argument(arg, type)` - Expand argument
- `parser.parse()` - Parse tokens to AST (delegates to specialized parsers)
- `parser.parse_with_error_collection()` - Parse with enhanced error collection (v0.85.0)
- `parser_factory.create_strict_posix_parser()` - Create POSIX-compliant parser (v0.85.0)
- `semantic_analyzer.analyze(ast)` - Perform semantic analysis (v0.85.0)
- `validation_pipeline.validate(ast)` - Run validation rules (v0.85.0)
- `ast_formatter.visit(ast)` - Format AST for display (v0.85.0)
- `visitor.visit(node)` - Execute AST node

## Maintenance

To keep this document updated:
1. Update version and date at top
2. Add new components to hierarchy
3. Update data flow if execution changes
4. Add new patterns as they emerge
5. Document new limitations discovered
6. Keep quick reference current

Related Documentation:
- `ARCHITECTURE.md` - Human-focused architecture guide (updated for v0.85.0)
- `PARSER_HIGH_PRIORITY_IMPLEMENTATION_PLAN.md` - Complete parser enhancement plan (implemented in v0.85.0)
- `CLAUDE_PARSER_IMPROVEMENTS.md` - Parser improvement analysis and implementation notes
- `PARSER_ARCHITECTURE.md` - Parser details (legacy)
- `docs/expansion_executor_architecture.md` - Expansion/execution details
- `docs/visitor_pattern_implementation.md` - Visitor pattern details
- `docs/architecture/lexer_architecture.md` - Comprehensive lexer architecture
- `LEXER_REFACTORING_PLAN.md` - Lexer refactoring phases and timeline (completed)