# PSH Architecture Reference for Large Language Models

Version: 0.180.0
Purpose: Optimized reference for LLMs working with the PSH codebase

## Quick Start

**Add a new builtin command**
1. Create module in `psh/builtins/` (example: `mycommand.py`) inheriting from `Builtin`
2. Apply the `@builtin` decorator to auto-register the class
3. Add behavioral tests in `tests/unit/builtins/` (or create a focused integration test under `tests/integration/builtins/`)

**Add a new shell option**
1. Extend `psh/core/state.py` to initialize the option in `ShellState.options`
2. Update any helpers in `psh/core/options.py` that should honor the option
3. Document CLI flags or builtin toggles if needed in `psh/builtins/parser_control.py`
4. Cover the option in `tests/integration/shell_options/test_shell_options_comprehensive.py`

**Modify parsing behavior**
1. Edit the appropriate module in `psh/parser/recursive_descent/parsers/` (e.g. `commands.py`, `control_structures.py`)
2. If context handling or configuration changes are required, adjust `ParserContext` in `psh/parser/recursive_descent/context.py`
3. Use `ParserConfig` (`psh/parser/config.py`) for feature flags; add presets via `ParserFactory` in `psh/parser/recursive_descent/support/factory.py`
4. Update validation or semantic rules in `psh/parser/validation/`
5. Add tests under `tests/test_parser_*.py` or `tests/unit/parser/`

**Extend expansion behavior**
1. Implement the feature in `psh/expansion/` (e.g., extend `parameter_expansion.py` or add a helper in `base.py`)
2. Register orchestration logic in `psh/expansion/manager.py`
3. Update ordering-sensitive logic in `ExpansionManager.expand_arguments()` (and relevant helpers)
4. Add unit tests in `tests/test_expansion_*.py`

**Add an AST visitor operation**
1. Create a visitor in `psh/visitor/` inheriting from `ASTVisitor`
2. Implement `visit_*` methods for the node types you care about
3. Wire the visitor into `Shell` or a command entry point if it becomes user-facing

## Component Hierarchy

```
psh/
├── shell.py                 # Main orchestrator (~316 lines, visitor executor only)
├── token_stream.py          # Parser-oriented token stream helpers
├── token_transformer.py     # Keyword/context normalization pass
├── pipeline/                # End-to-end pipeline builder utilities
│   └── builder.py
├── core/                    # Shared state, options, traps
│   ├── state.py             # ShellState and option plumbing
│   ├── scope.py             # Scope manager with POSIX semantics
│   ├── scope_enhanced.py    # Advanced scope features
│   ├── variables.py         # Variable types and exports
│   ├── exceptions.py        # Control-flow exceptions
│   └── trap_manager.py      # Signal/exit trap handling
├── lexer/                   # Unified modular lexer package
│   ├── modular_lexer.py     # Entry point for tokenization
│   ├── heredoc_lexer.py     # Tokenization with heredoc capture
│   ├── state_context.py     # Unified lexer context object
│   ├── transitions.py       # State machine transitions
│   ├── enhanced_context.py  # Rich metadata context helpers
│   ├── context_recognizer.py# Keyword and context detection
│   ├── quote_parser.py      # Unified quote parsing
│   ├── expansion_parser.py  # Pre-parse shell expansions
│   ├── expansion_validator.py
│   ├── quote_validator.py
│   ├── heredoc_collector.py
│   ├── token_stream_validator.py
│   ├── pure_helpers.py / token_parts.py / position.py / unicode_support.py
│   └── recognizers/         # Token recognizer registry (operators, keywords, literals, etc.)
├── token_types.py           # Unified Token & TokenType definitions
├── parser/                  # Parser packages and registries
│   ├── __init__.py          # Exports unified recursive-descent API
│   ├── config.py            # ParserConfig & enums
│   ├── recursive_descent/
│   │   ├── parser.py        # Main Parser class (composite-aware)
│   │   ├── base_context.py  # ContextBaseParser base class
│   │   ├── context.py       # ParserContext & profiler
│   │   ├── helpers.py       # TokenGroups & ParseError
│   │   ├── parsers/         # commands, control_structures, statements, arrays, etc.
│   │   └── support/         # context_factory, factory, utils, word_builder
│   ├── combinators/         # Modular parser-combinator implementation
│   ├── validation/          # Semantic analyzer & validation pipeline
│   └── visualization/       # AST renderers (ASCII, DOT, pretty)
├── expansion/               # POSIX expansion pipeline
│   ├── manager.py           # Orchestrates expansion order
│   ├── base.py              # Shared expansion helpers
│   ├── evaluator.py         # Word AST evaluation support
│   ├── variable.py / parameter_expansion.py
│   ├── command_sub.py / tilde.py / glob.py / word_splitter.py
├── executor/                # Visitor-based executor package
│   ├── core.py              # ExecutorVisitor (~312 lines, delegates to specialists)
│   ├── command.py / pipeline.py / control_flow.py
│   ├── array.py / function.py / subshell.py
│   ├── process_launcher.py  # Unified process creation
│   ├── child_policy.py / test_evaluator.py
│   ├── context.py           # ExecutionContext state management
│   └── strategies.py        # Builtin/function/external dispatch
├── io_redirect/             # Redirection management
│   ├── manager.py           # IOManager coordinating handlers
│   ├── file_redirect.py / heredoc.py / process_sub.py
├── scripting/               # Script execution pipeline
│   ├── base.py              # ScriptManager
│   ├── script_executor.py / source_processor.py
│   └── shebang_handler.py / script_validator.py
├── interactive/             # REPL, history, completion
│   ├── base.py              # InteractiveManager wiring
│   ├── repl_loop.py / prompt_manager.py / history_manager.py / signal_manager.py
│   └── completion_manager.py
├── brace_expansion.py / history_expansion.py / multiline_handler.py
├── builtins/                # Builtin commands (registry + implementations)
├── job_control.py           # Job control manager (JobManager)
└── utils/                   # Formatting helpers, path utilities, etc.
```

## Execution Pipeline

```
Input → Preprocessing → Tokenization → Token Normalization → Parsing → Validation → Expansion → Visitor Execution → Result
```

1. **Input Processing**
   - `input_preprocessing.py` handles line continuations
   - `history_expansion.HistoryExpander` expands `!` references
   - `brace_expansion.BraceExpander` expands `{…}` before lexing

2. **Tokenization (`psh/lexer/`)**
   - `ModularLexer` tokenizes with Unicode + contextual rules
   - `KeywordNormalizer` and `TokenTransformer` enforce context (case keywords, case terminators)
   - `tokenize_with_heredocs` collects heredoc bodies via `HeredocLexer`

3. **Token Post-processing**
   - `TokenStream` provides balanced collection, composite lookahead (`peek_composite_sequence()`), and helpers for parsers
   - Adjacent word-like tokens without whitespace are detected by `TokenStream` and built into composite `Word` AST nodes by `WordBuilder` during parsing
   - `token_stream_validator` ensures heredoc/token ordering sanity when integration requires it

4. **Parsing (`psh/parser/`)**
   - Default `Parser` (recursive descent) built from modular sub-parsers
   - `ParserContextFactory` wires contexts with config, tokens, and source text
   - `ParserFactory` produces preset configurations (strict POSIX, Bash-compatible, permissive, etc.)
   - Parser selection (`_active_parser` attribute) switches between recursive descent and parser-combinator implementations

5. **Validation (optional)**
   - `parser/validation/validation_pipeline.py` provides semantic analysis and warnings
   - Invoked explicitly via pipeline builder or shell options

6. **Expansion (`psh/expansion/`)**
   - `ExpansionManager` enforces POSIX ordering across tilde, parameter, command, arithmetic, word splitting, globbing, quote removal
   - `_expand_word()` walks `Word` AST parts using per-part quote context (no marker strings): single-quoted parts are literal, double-quoted expand variables but suppress splitting/globbing, unquoted parts get full expansion
   - `ExpansionEvaluator` evaluates expansion AST nodes (`VariableExpansion`, `ParameterExpansion`, `CommandSubstitution`, `ArithmeticExpansion`)

7. **Execution (`psh/executor/`)**
   - `ExecutorVisitor` walks AST nodes, leveraging specialized executors and `IOManager`
   - Returns final exit status; shell captures `$?`

## Orchestration & State

### Shell (`psh/shell.py`)
- Central entry point; orchestrates state, managers, parser strategy, and execution
- Initializes `ShellState`, alias/function/job managers, `ExpansionManager`, `IOManager`, `ScriptManager`, `InteractiveManager`, and `HistoryExpander`
- Uses `_active_parser` attribute to honor parser selection (recursive descent vs. combinators); child shells inherit parser choice
- Lazily instantiates `ExecutorVisitor` per execution to ensure fresh delegation wiring
- Key methods:
  - `run_command(cmd: str) -> int`
  - `execute_command_list(command_list: StatementList)`
  - `execute_toplevel(ast: TopLevel)` / `execute(ast)`
  - `execute_enhanced_test_statement(test_stmt: EnhancedTestStatement)`

### ShellState (`psh/core/state.py`)
- Centralizes environment, scope manager (`scope.py` / `scope_enhanced.py`), positional parameters, option flags, debug toggles, and stream references
- Tracks job control metadata, `$?`, `$!`, `$-`, and exported variables
- Provides option-specific helpers (xtrace, errexit, nounset) delegated to `psh/core/options.py`
- Coordinates trap installation through `TrapManager`

### Parser Integration Helpers
- Parser selection uses `shell._active_parser` attribute, switchable via `parser-select` builtin

## Token Pipeline Details

1. **Brace Expansion (`brace_expansion.py`)**
   - Expands `{a,b}` and ranges before lexing; failures fall back to raw input

2. **Modular Lexer (`lexer/modular_lexer.py`)**
   - Uses `state_context.py` and recognizer registry to emit unified `Token` instances
   - Uses `unicode_support.py` for identifier classification and POSIX fallback modes via `LexerConfig`
   - `recognizers/` includes operator, keyword, literal, whitespace, comment, and process-substitution recognizers

3. **Keyword Normalization & Token Transformation**
   - `lexer/keyword_normalizer.KeywordNormalizer` lowers + validates reserved words while preserving user identifiers; emits canonical keyword token types (e.g., WORD → THEN)
   - `token_transformer.TokenTransformer` enforces context rules (e.g., `;;` allowed only inside `case`)
   - Downstream code should match keywords via `matches_keyword`, `matches_keyword_type`, or `KeywordGuard` rather than inspecting `token.value`

4. **Token Stream Utilities (`token_stream.py`)**
   - Provides `peek`, `advance`, balance collection, composite lookahead (`peek_composite_sequence()`), and save/restore mechanics used across parser submodules
   - Adjacent tokens without whitespace (e.g., `foo${bar}.txt`) are detected via `adjacent_to_previous` token flags and built into composite `Word` AST nodes during parsing by `WordBuilder`

6. **Heredoc Support (`lexer/heredoc_lexer.py`, `lexer/heredoc_collector.py`)**
   - Collects heredoc bodies out-of-band while preserving token stream metadata
   - `tokenize_with_heredocs` returns `(tokens, heredoc_map)` for parser consumption

7. **Validation & Contracts**
   - `lexer/token_stream_validator.py` verifies lexer output contracts before parser integration when enhanced mode is active
   - `lexer/expansion_validator.py` / `lexer/quote_validator.py` provide sanity checks for complex lexing states

## Parser Package Highlights

### Recursive Descent Package (`psh/parser/recursive_descent/`)
- **`parser.py`**: Central `Parser` class orchestrating modular parsers; uses `ParserContextFactory` and exposes compatibility methods
- **`context.py`**: Defines `ParserContext`, profiling utilities, heredoc tracking, backtracking support
- **`base_context.py`**: Shared context-handling helpers (feature toggles, error policies)
- **`parsers/`**: Specialized modules for statements, commands, control structures, arithmetic, arrays, redirections, functions, and tests
- **`helpers.py`**: `ParseError`, `ErrorContext`, `TokenGroups`
- **`support/`**:
  - `context_factory.py`: Builds `ParserContext` from tokens/config
  - `factory.py`: Provides `ParserFactory` presets and configuration validation helpers
  - `utils.py`: Miscellaneous helpers (`parse_with_heredocs`, context adapters)
  - `word_builder.py`: Constructs Word AST nodes linking to expansion metadata

### Parser Configuration & Modes
- `parser/config.py`: `ParserConfig`, `ParsingMode`, `ErrorHandlingMode` with 14 fields (parsing mode, error handling, bash compatibility, validation)
- Parser selection: `psh/builtins/parser_experiment.py` provides `parser-select` builtin for runtime parser swapping
- `parser/validation/`: `SemanticAnalyzer`, `ValidationPipeline`, rule definitions, warnings, and symbol tables
- `parser/visualization/`: Formatters for pretty, DOT, ASCII, and S-expression AST outputs
- **Keyword Helper Lifecycle**:
  - Lexer: `KeywordNormalizer` converts raw `WORD` tokens into canonical keyword types and updates metadata (`SemanticType.KEYWORD`)
  - Parser: modules use `matches_keyword`, `matches_keyword_type`, or `KeywordGuard` instead of comparing `token.value`
  - Tooling: `tests/unit/tooling/test_keyword_comparisons.py` guards against new string comparisons; use allowlists only for legacy archived examples
  - AST/Errors: `Token.normalized_value` offers a canonical string for diagnostics and suggestions

### Alternative Implementation (`psh/parser/combinators/`)
- Fully modular parser-combinator implementation with near parity to recursive descent (`core.py`, `tokens.py`, `commands.py`, `control_structures.py`, etc.)
- Selected via `parser-select combinator` builtin (aliases: `"pc"`, `"functional"`)
- Used for experimentation, benchmarking, and educational comparisons

## Expansion System

- `expansion/manager.py` orchestrates all expansion phases and exposes debugging toggles
- `expansion/base.py` centralizes normalization helpers and shared exceptions
- `expansion/variable.py` / `parameter_expansion.py` handle `$var`, `${var}`, slicing, modifiers
- `expansion/command_sub.py` executes command substitutions, integrating with shell inheritance rules
- `expansion/tilde.py` resolves `~` and `~user`
- `expansion/glob.py` performs pathname expansion while respecting quoting
- `expansion/word_splitter.py` applies `$IFS`-aware splitting
- `expansion/evaluator.py` walks Word AST expansion nodes (`VariableExpansion`, `ParameterExpansion`, etc.)

## Execution & I/O

- `executor/core.py` implements `ExecutorVisitor`, delegating to specialized modules (`command.py`, `pipeline.py`, `control_flow.py`, `array.py`, `function.py`, `subshell.py`)
- `executor/process_launcher.py` provides unified process creation with job control:
  - **ProcessRole**: SINGLE, PIPELINE_LEADER, PIPELINE_MEMBER
  - **ProcessConfig**: role, pgid, foreground, sync pipes, I/O setup callback
  - **ProcessLauncher.launch()**: Single source of truth for all fork() calls
  - **Improvements (v0.103.0-v0.104.0)**:
    - C1: Pipe-based pipeline synchronization (replaces polling)
    - C2: Self-pipe SIGCHLD handler (async-safe signal handling)
    - C3: Unified process creation (eliminates duplication)
    - H3: Centralized child signal reset via required SignalManager
    - H4: Unified foreground job cleanup (JobManager.restore_shell_foreground)
    - H5: Surface terminal control failures (explicit tcsetpgrp error handling)
  - **Architecture Notes**: signal_manager is required parameter (no fallback code)
- `executor/strategies.py` encapsulates builtin/function/external command execution strategies
- `io_redirect/manager.py` coordinates file redirects, process substitutions, and heredoc handling; uses `FileRedirector`, `HeredocHandler`, `ProcessSubstitutionHandler`
- `job_control.JobManager` integrates job monitoring, shell options (`monitor`, `notify`), and process state tracking

## Supporting Systems

- `scripting/base.py` (`ScriptManager`) manages script execution, sourcing, and shebang handling
- `scripting/script_validator.py` / `source_processor.py` provide linting and pre-processing for scripts
- `interactive/base.py` coordinates REPL, prompt, history, and signal managers; `repl_loop.py` drives interactive shells
- `input_sources.py`, `multiline_handler.py`, `line_editor.py` support multi-line editing and input abstraction
- `utils/token_formatter.py` and friends provide debugging/trace formatting

## Data Flow Examples

### Simple Command: `echo "Hello $USER"`
1. **Tokenizer**: WORD(`echo`), STRING(`Hello $USER`)
2. **Parser**: `SimpleCommand(args=["echo", "Hello $USER"], words=[Word("echo"), Word(parts=[LiteralPart("Hello "), ExpansionPart(VariableExpansion("USER"))], quote_type='"')])`
3. **Expansion**: Word AST walk — double-quoted word expands variables but suppresses splitting/globbing → `"Hello alice"`
4. **Executor**: Runs builtin `echo`, returns status `0`

### Composite Argument: `file${N}.txt`
1. **Tokenizer**: WORD(`file`), VARIABLE(`N`), WORD(`.txt`) — adjacent (no whitespace)
2. **Parser**: `WordBuilder.build_composite_word()` merges into single `Word(parts=[LiteralPart("file"), ExpansionPart(ParameterExpansion("N")), LiteralPart(".txt")])`
3. **Expansion**: Per-part expansion using Word AST quote context; variable expansion occurs preserving literal parts

### Pipeline: `ls | grep test`
1. **Tokenizer**: `ModularLexer` produces WORD(`ls`), PIPE, WORD(`grep`), WORD(`test`)
2. **Parser**: Produces `Pipeline([SimpleCommand("ls"), SimpleCommand("grep", "test")])`
3. **ExecutorVisitor**: Sets up pipe, forks commands, returns exit status of final command (with `pipefail` awareness)

## Extension Points

**New Builtin Command**
```python
# psh/builtins/mybuiltin.py
from psh.builtins.base import Builtin
from psh.builtins.registry import builtin

@builtin
class MyBuiltin(Builtin):
    name = "mybuiltin"

    def execute(self, args: list[str], shell: 'Shell') -> int:
        # Implementation
        return 0
```

**New Parser Rule**
1. Add parsing logic in the relevant module under `psh/parser/recursive_descent/parsers/`
2. Update helper utilities or token groups if the rule needs new token classifications
3. Provide validation rules in `psh/parser/validation/validation_rules.py` if semantics require checks

**New Expansion Type**
1. Implement expander in `psh/expansion/` (e.g., `new_expansion.py`)
2. Invoke it from `ExpansionManager.expand_arguments()` (or the specific helper it delegates to) in the proper POSIX order slot
3. Update `ExpansionEvaluator` when Word AST integration is required
4. Add regression coverage in `tests/test_expansion_new_feature.py`

## Architecture Invariants

1. **Centralized State**: All mutable shell state flows through `ShellState`
2. **Component Isolation**: Managers interact via `Shell` references, not global state
3. **Visitor Execution**: AST nodes remain data-only; behavior lives in visitors/executors
4. **POSIX Expansion Order**: Expansion phases must remain in standard order
5. **Parser Feature Flags**: `ParserConfig` governs all behavior toggles; avoid hard-coded feature switches
6. **Word AST as Source of Truth**: `SimpleCommand.words` is the sole structural representation for argument metadata (quoting, expansion types). Use Word helper properties (`is_quoted`, `is_unquoted_literal`, `is_variable_expansion`, `has_expansion_parts`, `has_unquoted_expansion`, `effective_quote_char`) instead of string-based type checks. The legacy `arg_types`/`quote_types` fields were removed in v0.120.0.
7. **Exit Status Discipline**: Every execution path returns an integer exit status

## Testing Conventions

- Pytest entry: `pytest` (configured via `pytest.ini`)
- Tests live in `tests/`; place focused parser/unit work under `tests/unit/`
- Lexer tests: `tests/test_lexer_*.py` (add new focused cases alongside existing files); keyword normalization goldens live in `tests/unit/lexer/test_keyword_normalizer_golden.py`
- Parser tests: `tests/test_parser_*.py`, combinator parity suites in `tests/unit/parser/`
- Parser parity: `tests/test_parser_feature_parity.py` has keyword-heavy scenarios to keep recursive descent and combinator implementations aligned
- Expansion tests: `tests/test_expansion_*.py`
- Executor/integration: `tests/test_executor_*.py`, `tests/test_shell_*.py`, plus golden scripts in `conformance_tests/`
- Tooling checks: `tests/unit/tooling/test_keyword_comparisons.py` prevents new raw keyword comparisons
- Use fixtures from `conftest.py` (`shell`, `tokenizer`, etc.) for consistency

## Performance Considerations

1. **Lexer**: State machine minimizes backtracking; Unicode classification cached in helpers
2. **Parser**: Modular recursive descent with shared `ParserContext` reduces redundant allocations; `TokenStream.peek_composite_sequence()` detects adjacent tokens efficiently
3. **Validation**: Optional; keep disabled in performance-sensitive modes
4. **Executor**: Strategy pattern avoids repeated type checks and supports caching
5. **Expansion**: Word AST walk provides per-part quote context without marker strings; lazy evaluation where possible

## Known Limitations

1. **Python Recursion Limits**: Deeply nested shell functions may exceed Python recursion depth
2. **Pytest Output Capture**: Command substitution may interfere with pytest's stdout capture in certain tests; subshell tests require `-s` flag
3. **Builtin Redirections**: Builtins re-use process substitution & FD juggling; some complex redirection combinations still require caution

## Quick Reference

- **Add builtin**: `psh/builtins/` + `psh/builtins/registry.py`
- **Modify tokenization**: `psh/lexer/modular_lexer.py` and recognizers; configs via `LexerConfig` in `psh/lexer/position.py`
- **Keyword normalization**: `psh/lexer/keyword_normalizer.py`
- **Token transformation**: `psh/token_transformer.py`
- **Token stream utilities**: `psh/token_stream.py`
- **Parser entry point**: `psh/parser/__init__.py` (`parse`, `ParserFactory`)
- **Parser context**: `psh/parser/recursive_descent/context.py`
- **Parser presets**: `psh/parser/recursive_descent/support/factory.py`
- **Parser selection**: `psh/builtins/parser_experiment.py` (`parser-select` builtin)
- **Parser validation**: `psh/parser/validation/validation_pipeline.py`
- **Expansion manager**: `psh/expansion/manager.py`
- **Executor visitor**: `psh/executor/core.py`
- **IO manager**: `psh/io_redirect/manager.py`
- **Shell options**: `psh/core/state.py`, behaviors in `psh/core/options.py`
- **Job control**: `psh/job_control.py`
- **Interactive shell**: `psh/interactive/base.py`, `psh/interactive/repl_loop.py`
- **Script execution**: `psh/scripting/base.py`, `psh/scripting/script_executor.py`

## Maintenance

1. Update version/date header when architecture changes land (`psh/version.py` authoritative)
2. Refresh component hierarchy for new modules or reorganizations
3. Adjust execution pipeline notes when token/parsing steps shift
4. Keep extension points and quick reference aligned with latest module paths
5. Cross-check against `ARCHITECTURE.md` and release notes; this file supersedes older human-focused docs when conflicts arise
6. Document new invariants and known limitations as they appear

Related documentation:
- `ARCHITECTURE.md` – human-readable guide
- `CHANGELOG.md` and `psh/version.py` – change history
- `CLAUDE.md`, `AGENTS.md` – collaboration guidelines for agentic contributors
- `docs/keyword_helper_cookbook.md` – practical guide for keyword normalization and parser integration
- `docs/architecture_recommendations.md` – ongoing suggestions for structural improvements and refactors
